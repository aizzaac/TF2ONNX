{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF_to_ONNX.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOaCAQZp/o+wfrF853S58kP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aizzaac/TF2ONNX/blob/main/TF_to_ONNX.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fW2tuPdJXsbo"
      },
      "source": [
        "# **Verify TensorFlow version**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtznbvvIqCdZ",
        "outputId": "ddfc61ab-ad24-430e-962e-527d0ce9f7d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "# Import tensorflow 1.x \n",
        "%tensorflow_version 1.x\n",
        "!pip show tensorflow  #To see the TF version available"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Name: tensorflow\n",
            "Version: 1.15.2\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /tensorflow-1.15.2/python3.6\n",
            "Requires: absl-py, keras-applications, google-pasta, opt-einsum, wrapt, wheel, astor, numpy, six, protobuf, grpcio, tensorboard, termcolor, keras-preprocessing, gast, tensorflow-estimator\n",
            "Required-by: stable-baselines, magenta, fancyimpute\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiNL801lX0Gd"
      },
      "source": [
        "# **Install tf2onnx and onnxruntime**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hv6KAsznrYLg",
        "outputId": "2d464a11-5d1f-400c-9ceb-eda566bd34c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        }
      },
      "source": [
        "##Install tf2onnx and onnxruntime\n",
        "##https://github.com/onnx/tensorflow-onnx\n",
        "!pip install --user -U tf2onnx #Install from pypi\n",
        "#!pip install --user -U onnxruntime #(optional) If you want to run tests using ONNX models"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tf2onnx\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/77/82/80cc3ddb4d1adb8250f83b5f27d9fb203c1549a3acf26d7ebc9309a20931/tf2onnx-1.7.1-py3-none-any.whl (194kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from tf2onnx) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from tf2onnx) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.14.1 in /usr/local/lib/python3.6/dist-packages (from tf2onnx) (1.18.5)\n",
            "Collecting onnx>=1.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/ee/bc7bc88fc8449266add978627e90c363069211584b937fd867b0ccc59f09/onnx-1.7.0-cp36-cp36m-manylinux1_x86_64.whl (7.4MB)\n",
            "\u001b[K     |████████████████████████████████| 7.4MB 7.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->tf2onnx) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->tf2onnx) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->tf2onnx) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->tf2onnx) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: protobuf in /usr/local/lib/python3.6/dist-packages (from onnx>=1.4.1->tf2onnx) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.6/dist-packages (from onnx>=1.4.1->tf2onnx) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->onnx>=1.4.1->tf2onnx) (50.3.0)\n",
            "Installing collected packages: onnx, tf2onnx\n",
            "\u001b[33m  WARNING: The scripts backend-test-tools, check-model and check-node are installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
            "Successfully installed onnx-1.7.0 tf2onnx-1.7.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ks0cAyQRYlla"
      },
      "source": [
        "# **Cloning the repository**\n",
        "**tf2onnx - convert TensorFlow models to ONNX**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSJHRaTgsN86",
        "outputId": "8a96b894-02fd-4279-fbf1-a57fec0291df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "!git clone https://github.com/onnx/tensorflow-onnx"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'tensorflow-onnx'...\n",
            "remote: Enumerating objects: 18, done.\u001b[K\n",
            "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 10664 (delta 7), reused 11 (delta 3), pack-reused 10646\u001b[K\n",
            "Receiving objects: 100% (10664/10664), 20.96 MiB | 29.64 MiB/s, done.\n",
            "Resolving deltas: 100% (7972/7972), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkcXu_JnZZBm"
      },
      "source": [
        "# **Calling: \"setup.py\"**\n",
        "https://github.com/onnx/tensorflow-onnx/blob/master/setup.py\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BN2oMILps1QR",
        "outputId": "6a424e03-4dbd-4c9b-f889-973f872b8072",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "##Once dependencies are installed, from the tensorflow-onnx folder call:\n",
        "%cd /content/tensorflow-onnx ##\"content\" is the folder where the GIT has been cloned\n",
        "!python setup.py install"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: '/content/tensorflow-onnx #content is the folder where the GIT has been cloned'\n",
            "/content\n",
            "python3: can't open file 'setup.py': [Errno 2] No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpMRcMQUc6nc"
      },
      "source": [
        "# **Downloading the pretrained models**\n",
        "1.   From the Tensorflow's zoo: https://github.com/tensorflow/models/tree/master/research/slim\n",
        "2.   From ONNX's zoo:\n",
        " https://github.com/onnx/tensorflow-onnx/blob/master/tests/run_pretrained_models.yaml"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5z7uT2gj_2w",
        "outputId": "ebf835e1-dd63-4853-9113-7687c40cb181",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "##Let's download the pretrained models from tensorflow's model zoo OR from ONNX's zoo\n",
        "%mkdir /content/pretrained_model ##creating a new folder for the \"pretrained models\"\n",
        "%cd /content/pretrained_model/ ##accessing the previous folder"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/content/pretrained_model’: File exists\n",
            "[Errno 2] No such file or directory: '/content/pretrained_model/ #accessing the previous folder'\n",
            "/content/pretrained_model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5ykXgwIupJ-",
        "outputId": "a9e8e56f-afd2-434a-cd2f-af150644bf8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 886
        }
      },
      "source": [
        "##InceptionV1\n",
        "!wget https://storage.googleapis.com/download.tensorflow.org/models/inception_v1_2016_08_28_frozen.pb.tar.gz\n",
        "!tar xvf inception_v1_2016_08_28_frozen.pb.tar.gz\n",
        "\n",
        "\n",
        "##InceptionV2**\n",
        "!wget https://storage.googleapis.com/download.tensorflow.org/models/inception_v2_2016_08_28_frozen.pb.tar.gz\n",
        "!tar xvf inception_v2_2016_08_28_frozen.pb.tar.gz\n",
        "\n",
        "\n",
        "##InceptionV3\n",
        "!wget https://storage.googleapis.com/download.tensorflow.org/models/inception_v3_2016_08_28_frozen.pb.tar.gz\n",
        "!tar xvf inception_v3_2016_08_28_frozen.pb.tar.gz\n",
        "\n",
        "\n",
        "##InceptionV4\n",
        "!wget https://storage.googleapis.com/download.tensorflow.org/models/inception_v4_2016_09_09_frozen.pb.tar.gz\n",
        "!tar xvf inception_v4_2016_09_09_frozen.pb.tar.gz\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-12 21:13:41--  https://storage.googleapis.com/download.tensorflow.org/models/inception_v1_2016_08_28_frozen.pb.tar.gz\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.216.128, 173.194.217.128, 108.177.11.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.216.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 24695710 (24M) [application/gzip]\n",
            "Saving to: ‘inception_v1_2016_08_28_frozen.pb.tar.gz.1’\n",
            "\n",
            "inception_v1_2016_0 100%[===================>]  23.55M   142MB/s    in 0.2s    \n",
            "\n",
            "2020-10-12 21:13:41 (142 MB/s) - ‘inception_v1_2016_08_28_frozen.pb.tar.gz.1’ saved [24695710/24695710]\n",
            "\n",
            "inception_v1_2016_08_28_frozen.pb\n",
            "imagenet_slim_labels.txt\n",
            "--2020-10-12 21:13:42--  https://storage.googleapis.com/download.tensorflow.org/models/inception_v2_2016_08_28_frozen.pb.tar.gz\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.204.128, 173.194.216.128, 2607:f8b0:400c:c03::80, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.204.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 41650336 (40M) [application/gzip]\n",
            "Saving to: ‘inception_v2_2016_08_28_frozen.pb.tar.gz.1’\n",
            "\n",
            "inception_v2_2016_0 100%[===================>]  39.72M   138MB/s    in 0.3s    \n",
            "\n",
            "2020-10-12 21:13:42 (138 MB/s) - ‘inception_v2_2016_08_28_frozen.pb.tar.gz.1’ saved [41650336/41650336]\n",
            "\n",
            "inception_v2_2016_08_28_frozen.pb\n",
            "imagenet_slim_labels.txt\n",
            "--2020-10-12 21:13:43--  https://storage.googleapis.com/download.tensorflow.org/models/inception_v3_2016_08_28_frozen.pb.tar.gz\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.204.128, 74.125.134.128, 2607:f8b0:400c:c03::80, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.204.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 88668554 (85M) [application/gzip]\n",
            "Saving to: ‘inception_v3_2016_08_28_frozen.pb.tar.gz.1’\n",
            "\n",
            "inception_v3_2016_0 100%[===================>]  84.56M  60.4MB/s    in 1.4s    \n",
            "\n",
            "2020-10-12 21:13:45 (60.4 MB/s) - ‘inception_v3_2016_08_28_frozen.pb.tar.gz.1’ saved [88668554/88668554]\n",
            "\n",
            "inception_v3_2016_08_28_frozen.pb\n",
            "imagenet_slim_labels.txt\n",
            "--2020-10-12 21:13:46--  https://storage.googleapis.com/download.tensorflow.org/models/inception_v4_2016_09_09_frozen.pb.tar.gz\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.31.128, 173.194.217.128, 172.217.193.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.31.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 158921418 (152M) [application/gzip]\n",
            "Saving to: ‘inception_v4_2016_09_09_frozen.pb.tar.gz’\n",
            "\n",
            "inception_v4_2016_0 100%[===================>] 151.56M   115MB/s    in 1.3s    \n",
            "\n",
            "2020-10-12 21:13:48 (115 MB/s) - ‘inception_v4_2016_09_09_frozen.pb.tar.gz’ saved [158921418/158921418]\n",
            "\n",
            "inception_v4_2016_09_09_frozen.pb\n",
            "imagenet_slim_labels.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RY6YguEfqa8N"
      },
      "source": [
        "# **Specifying inputs and outputs for each model**\n",
        "python3 -m tf2onnx.convert \\\n",
        "\n",
        "--graphdef -> PATH TO TF MODEL\n",
        "\n",
        "--output ->   PATH AND NAME TO ONNX FILE\n",
        "\n",
        "--inputs  -> INPUT NODES \n",
        "\n",
        "--outputs -> OUTPUT NODES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIL1gqq2yB37",
        "outputId": "08d4426d-20e7-4421-cd3c-666a2ffa3786",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "##As I have a frozen graph, I need to specify inputs and outputs: INCEPTION_V1\n",
        "!python3 -m tf2onnx.convert \\\n",
        "--graphdef /content/pretrained_model/inception_v1_2016_08_28_frozen.pb \\\n",
        "--output /content/pretrained_model/inception_v1_2016_08_28_frozen.onnx \\\n",
        "--inputs input:0 \\\n",
        "--outputs InceptionV1/Logits/Predictions/Softmax:0"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /root/.local/lib/python3.6/site-packages/tf2onnx/verbose_logging.py:76: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "2020-10-12 21:45:15,627 - WARNING - From /root/.local/lib/python3.6/site-packages/tf2onnx/verbose_logging.py:76: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "2020-10-12 21:45:15.638741: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2020-10-12 21:45:16,607 - INFO - Using tensorflow=1.15.2, onnx=1.7.0, tf2onnx=1.7.1/796841\n",
            "2020-10-12 21:45:16,607 - INFO - Using opset <onnx, 8>\n",
            "2020-10-12 21:45:17,370 - INFO - Computed 0 values for constant folding\n",
            "2020-10-12 21:45:19,237 - INFO - Optimizing ONNX model\n",
            "2020-10-12 21:45:19,889 - INFO - After optimization: Add -57 (57->0), Cast -1 (1->0), Const -9 (126->117), Identity -2 (2->0), Transpose -143 (144->1)\n",
            "2020-10-12 21:45:19,904 - INFO - \n",
            "2020-10-12 21:45:19,905 - INFO - Successfully converted TensorFlow model /content/pretrained_model/inception_v1_2016_08_28_frozen.pb to ONNX\n",
            "2020-10-12 21:45:19,933 - INFO - ONNX model is saved at /content/pretrained_model/inception_v1_2016_08_28_frozen.onnx\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJ3Xiwc4sw9k",
        "outputId": "6c66fbd6-2b0b-42cc-c761-6f721828588e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "##As I have a frozen graph, I need to specify inputs and outputs: INCEPTION_V2\n",
        "!python3 -m tf2onnx.convert \\\n",
        "--graphdef /content/pretrained_model/inception_v2_2016_08_28_frozen.pb \\\n",
        "--output /content/pretrained_model/inception_v2_2016_08_28_frozen.onnx \\\n",
        "--inputs input:0 \\\n",
        "--outputs InceptionV2/Predictions/Softmax:0"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /root/.local/lib/python3.6/site-packages/tf2onnx/verbose_logging.py:76: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "2020-10-12 21:35:50,769 - WARNING - From /root/.local/lib/python3.6/site-packages/tf2onnx/verbose_logging.py:76: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "2020-10-12 21:35:50.864999: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2020-10-12 21:35:52,624 - INFO - Using tensorflow=1.15.2, onnx=1.7.0, tf2onnx=1.7.1/796841\n",
            "2020-10-12 21:35:52,624 - INFO - Using opset <onnx, 8>\n",
            "2020-10-12 21:35:53,895 - INFO - Computed 0 values for constant folding\n",
            "2020-10-12 21:35:58,854 - INFO - Optimizing ONNX model\n",
            "2020-10-12 21:36:00,170 - INFO - After optimization: Add -68 (68->0), Cast -1 (1->0), Const -10 (152->142), Identity -2 (2->0), Transpose -167 (168->1)\n",
            "2020-10-12 21:36:00,200 - INFO - \n",
            "2020-10-12 21:36:00,200 - INFO - Successfully converted TensorFlow model /content/pretrained_model/inception_v2_2016_08_28_frozen.pb to ONNX\n",
            "2020-10-12 21:36:00,543 - INFO - ONNX model is saved at /content/pretrained_model/inception_v2_2016_08_28_frozen.onnx\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qYHv_pQvTk3",
        "outputId": "051d00ce-ee41-4f09-d5ba-a8a2856ca79f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "##As I have a frozen graph, I need to specify inputs and outputs: INCEPTION_V3\n",
        "!python3 -m tf2onnx.convert \\\n",
        "--graphdef /content/pretrained_model/inception_v3_2016_08_28_frozen.pb \\\n",
        "--output /content/pretrained_model/inception_v3_2016_08_28_frozen.onnx \\\n",
        "--inputs input:0 \\\n",
        "--outputs InceptionV3/Predictions/Softmax:0"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /root/.local/lib/python3.6/site-packages/tf2onnx/verbose_logging.py:76: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "2020-10-12 21:38:13,432 - WARNING - From /root/.local/lib/python3.6/site-packages/tf2onnx/verbose_logging.py:76: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "2020-10-12 21:38:13.443818: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2020-10-12 21:38:16,479 - INFO - Using tensorflow=1.15.2, onnx=1.7.0, tf2onnx=1.7.1/796841\n",
            "2020-10-12 21:38:16,479 - INFO - Using opset <onnx, 8>\n",
            "2020-10-12 21:38:19,137 - INFO - Computed 0 values for constant folding\n",
            "2020-10-12 21:38:25,500 - INFO - Optimizing ONNX model\n",
            "2020-10-12 21:38:26,644 - INFO - After optimization: Add -94 (94->0), Cast -1 (1->0), Const -11 (202->191), Identity -2 (2->0), Transpose -217 (218->1)\n",
            "2020-10-12 21:38:26,669 - INFO - \n",
            "2020-10-12 21:38:26,669 - INFO - Successfully converted TensorFlow model /content/pretrained_model/inception_v3_2016_08_28_frozen.pb to ONNX\n",
            "2020-10-12 21:38:26,805 - INFO - ONNX model is saved at /content/pretrained_model/inception_v3_2016_08_28_frozen.onnx\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXb9fWKev9sZ",
        "outputId": "09cc11a1-d832-4850-af04-f8f95c128968",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "##As I have a frozen graph, I need to specify inputs and outputs: INCEPTION_V4\n",
        "!python3 -m tf2onnx.convert \\\n",
        "--graphdef /content/pretrained_model/inception_v4_2016_09_09_frozen.pb \\\n",
        "--output /content/pretrained_model/inception_v4_2016_09_09_frozen.onnx \\\n",
        "--inputs input:0 \\\n",
        "--outputs InceptionV4/Logits/Predictions:0"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /root/.local/lib/python3.6/site-packages/tf2onnx/verbose_logging.py:76: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "2020-10-12 21:40:58,442 - WARNING - From /root/.local/lib/python3.6/site-packages/tf2onnx/verbose_logging.py:76: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "2020-10-12 21:40:58.453533: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2020-10-12 21:41:03,827 - INFO - Using tensorflow=1.15.2, onnx=1.7.0, tf2onnx=1.7.1/796841\n",
            "2020-10-12 21:41:03,827 - INFO - Using opset <onnx, 8>\n",
            "2020-10-12 21:41:08,531 - INFO - Computed 0 values for constant folding\n",
            "2020-10-12 21:41:20,065 - INFO - Optimizing ONNX model\n",
            "2020-10-12 21:41:22,251 - INFO - After optimization: Add -149 (149->0), Cast -1 (1->0), Const -18 (320->302), Identity -2 (2->0), Reshape +1 (1->2), Transpose -335 (336->1)\n",
            "2020-10-12 21:41:22,296 - INFO - \n",
            "2020-10-12 21:41:22,296 - INFO - Successfully converted TensorFlow model /content/pretrained_model/inception_v4_2016_09_09_frozen.pb to ONNX\n",
            "2020-10-12 21:41:22,590 - INFO - ONNX model is saved at /content/pretrained_model/inception_v4_2016_09_09_frozen.onnx\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmcrH_45xlka"
      },
      "source": [
        "# **Downloading the pretrained_model folder:.onnx, .pb, .pb.tar.gz)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1mAUtEmy3X5",
        "outputId": "42f0a15a-84d5-4155-f45e-bfd375762f80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        }
      },
      "source": [
        "##Download the \"onnx\" and \"frozen\" models\n",
        "from google.colab import files\n",
        "%cd /content/ \n",
        "\n",
        "!tar cvf TF_to_ONNX.tar.gz pretrained_model ##compressing the folder\n",
        "files.download('/content/TF_to_ONNX.tar.gz')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pretrained_model/\n",
            "pretrained_model/inception_v2_2016_08_28_frozen.pb\n",
            "pretrained_model/inception_v3_2016_08_28_frozen.onnx\n",
            "pretrained_model/inception_v2_2016_08_28_frozen.onnx\n",
            "pretrained_model/inception_v1_2016_08_28_frozen.pb\n",
            "pretrained_model/inception_v2_2016_08_28_frozen.pb.tar.gz\n",
            "pretrained_model/inception_v4_2016_09_09_frozen.pb.tar.gz\n",
            "pretrained_model/inception_v1_2016_08_28_frozen.onnx\n",
            "pretrained_model/.ipynb_checkpoints/\n",
            "pretrained_model/inception_v4_2016_09_09_frozen.onnx\n",
            "pretrained_model/inception_v1_2016_08_28_frozen.pb.tar.gz\n",
            "pretrained_model/imagenet_slim_labels.txt\n",
            "pretrained_model/inception_v4_2016_09_09_frozen.pb\n",
            "pretrained_model/inception_v3_2016_08_28_frozen.pb\n",
            "pretrained_model/inception_v3_2016_08_28_frozen.pb.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_1ae2a28e-04cf-403f-8e6f-c8aefecd412b\", \"TF_to_ONNX.tar.gz\", 990300160)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJaIC9wwQLkA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}